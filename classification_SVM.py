# -*- coding: utf-8 -*-

"""
@author: Srikanth
"""

import os
import numpy as np
import gzip

from csv import reader, writer
import six
import ast
import matplotlib.pyplot as plt

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.cross_validation import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier


# Decide read/write mode based on python version
read_mode, write_mode = ('r','w') if six.PY2 else ('rt','wt')

# Decide zip based on python version
if six.PY2:
    from itertools import izip
    zp = izip
else:
    zp = zip


# Set path to your consolidated files
path = '/root/hackathon/'

os.chdir(path)

# File names
ftrain = 'train_consolidation.gz'
ftest = 'test_consolidation.gz'
flabel = 'trainLabels.csv'

print('loading started')

# Lets read labels first as things are not sorted in files

labels = {}

with open(flabel) as f:
    for row in reader(f):
        labels[row[0]] = int(row[1])

print('labels loaded')

# Dimensions for train set

ntrain = 500
nfeature = 16**2 + 1 + 1 # For two_byte_codes, no_que_marks, label
train = np.zeros((ntrain, nfeature), dtype = int)

with gzip.open(ftrain, read_mode) as f:
    next(f)    # Ignoring header

    for t,row in enumerate(reader(f)):
        train[t,:-1] = map(int, row[1:]) if six.PY2 else list(map(int, row[1:]))
	print row[0]
        train[t,-1] = labels[row[0]]
	print t
        if(t+1)%100==0:
            print(t+1, 'records loaded')

print "Before Binarizing labels"
# Binarize the output
labels = label_binarize(labels.values(), classes=[1,2,3,4,5,6,7,8,9])
print labels
n_classes = labels.shape[1]
print "After Binarizing labels"

# Add additional noisy features
random_state = np.random.RandomState(0)
n_samples, n_features = train.shape

print "Ready for training"
print "n_samples = %s" % n_samples
print "n_features = %s" % n_features

# shuffle and split training and test sets
X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=.3, random_state=0)

print "After train test split"
print X_train[1]
print X_test[1]
print y_train[1]
print y_test[1]

# Learn to predict each class against the other
classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,
                                 random_state=random_state))
print "Created the classifier. Ready to fit."
y_score = classifier.fit(X_train, y_train).decision_function(X_test)
print "After fitting the data. Ready to plot."
print X_test
print y_score


# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
print roc_auc
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
    print roc_auc[i]

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
print roc_auc["micro"]

# Plot of a ROC curve for a specific class
plt.figure()
plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()

# Plot ROC curve
plt.figure()
plt.plot(fpr["micro"], tpr["micro"],
         label='micro-average ROC curve (area = {0:0.2f})'
               ''.format(roc_auc["micro"]))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'
                                   ''.format(i, roc_auc[i]))

